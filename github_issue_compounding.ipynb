{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "tflite_quant_params_compounding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('tf-exp': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "1dd3f7e8b9281c263f9ccce33e0991d02fffaeb6afe0c0436aa5cbe473145776"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "metadata": {
        "id": "fBel3RL1ODa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the errors compound with more layers.\n",
        "\n",
        "We compare the output of successive manual computations, with the tflite model."
      ],
      "metadata": {
        "id": "YQKPowPAOXAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Computation"
      ],
      "metadata": {
        "id": "cdlTLgl-OeJI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# manual computation\n",
        "rng = np.random.RandomState(0)\n",
        "x = rng.uniform(0, 1, size=(32, 10))\n",
        "w = rng.uniform(-1, 1, size=(10, 10))\n",
        "N_LAYERS = 5\n",
        "\n",
        "# As per TfLite's QuantizeModel https://git.io/J4hxt, it seems that a full fp32 forward pass is done\n",
        "# after which, quantization parameters are independantly calculated. Then, the model is 'quantized'\n",
        "\n",
        "# Run fp32 forward pass\n",
        "manual_output = x\n",
        "fp32_outputs = []\n",
        "for _ in range(N_LAYERS):\n",
        "    manual_output = tf.matmul(manual_output, w)\n",
        "    fp32_outputs.append(manual_output)\n",
        "\n",
        "# Run quantized pass after 'computing' quantization parameters\n",
        "w_quant = tf.quantization.fake_quant_with_min_max_args(\n",
        "    w, min(np.min(w), -np.max(w)), max(np.max(w), -np.min(w)), narrow_range=True\n",
        ")\n",
        "\n",
        "\n",
        "manual_output = tf.quantization.fake_quant_with_min_max_args(x, np.min(x), np.max(x))\n",
        "for i in range(N_LAYERS):\n",
        "    manual_output = tf.matmul(manual_output, w_quant)\n",
        "    manual_output = tf.quantization.fake_quant_with_min_max_args(\n",
        "        manual_output,\n",
        "        np.min(fp32_outputs[i]),\n",
        "        np.max(fp32_outputs[i])\n",
        "        # Use min/max of fp32 forward pass for quantization parameters\n",
        "    )\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "VYT2DLjzOD8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLite Computation"
      ],
      "metadata": {
        "id": "DOIYfnK5OkGv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# tflite computation\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(\n",
        "            10, use_bias=False, kernel_initializer=tf.initializers.constant(w)\n",
        "        )\n",
        "        for _ in range(N_LAYERS)\n",
        "    ]\n",
        ")\n",
        "model.build(x.shape)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "yPDURL8EPB-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def representative_dataset():\n",
        "    for i in range(x.shape[0]):\n",
        "        yield [x[[i]].astype(np.float32)]\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=converter.convert())\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "x_quant = np.round(x / input_scale + input_zero_point).astype(np.uint8)\n",
        "interpreter.set_tensor(input_details[\"index\"], x_quant)\n",
        "interpreter.invoke()\n",
        "tflite_output = interpreter.get_tensor(output_details[\"index\"])\n",
        "output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "tflite_output = (tflite_output.astype(np.float32) - output_zero_point) * output_scale"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpcev_9c14/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apNlAwDhOEQ0",
        "outputId": "fb419e71-d224-45ef-e1ca-edba5db4f6e3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Outputs"
      ],
      "metadata": {
        "id": "burB6wxbOntc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# compare outputs\n",
        "outputs_close = np.allclose(manual_output, tflite_output, rtol=0, atol=1e-2)\n",
        "# Number of elements not within the tolerance\n",
        "num_mismatch = np.count_nonzero(~np.isclose(manual_output, tflite_output, rtol=0, atol=1e-2))\n",
        "err = np.abs(manual_output - tflite_output)\n",
        "with warnings.catch_warnings():\n",
        "    # Ignore \"divide by zero\" RuntimeWarning\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    err_rel = err / np.abs(tflite_output)\n",
        "# Filter out nan and inf created by dividing by 0\n",
        "err_rel = err_rel[np.isfinite(err_rel)]\n",
        "print(f\"--------------------- Manual vs TFLite ---------------------\")\n",
        "print(f\"Max Error: {np.max(err)}\")\n",
        "print(f\"Max Relative Error: {np.max(err_rel)}\")\n",
        "print(f\"Mean Error: {np.mean(err)}\")\n",
        "print(f\"Number of outputs outside tolerance: {num_mismatch/x.size*100}% of {x.size}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------- Manual vs TFLite ---------------------\n",
            "Max Error: 0.5703296661376953\n",
            "Max Relative Error: 1.0\n",
            "Mean Error: 0.10159063339233398\n",
            "Number of outputs outside tolerance: 31.25% of 320\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbo3jxWEN6Se",
        "outputId": "0c77c7f0-2c1d-48ae-a42a-ed50a5ff5610"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see above that the error compounds with more layers"
      ],
      "metadata": {
        "id": "S5QAO0LJOrYI"
      }
    }
  ]
}