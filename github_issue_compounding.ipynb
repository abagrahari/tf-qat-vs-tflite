{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tflite_quant_params_compounding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBel3RL1ODa0"
      },
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQKPowPAOXAt"
      },
      "source": [
        "Let's see how the errors compound with more layers.\n",
        "\n",
        "We compare the output of successive manual computations, with the tflite model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdlTLgl-OeJI"
      },
      "source": [
        "# Manual Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYT2DLjzOD8l"
      },
      "source": [
        "# manual computation\n",
        "rng = np.random.RandomState(0)\n",
        "x = rng.uniform(0, 1, size=(32, 10))\n",
        "w = rng.uniform(-1, 1, size=(10, 10))\n",
        "N_LAYERS = 5\n",
        "w_quant = tf.quantization.fake_quant_with_min_max_args(\n",
        "    w, min(np.min(w), -np.max(w)), max(np.max(w), -np.min(w)), narrow_range=True\n",
        ")\n",
        "manual_output = x\n",
        "for _ in range(N_LAYERS):\n",
        "    manual_output = tf.quantization.fake_quant_with_min_max_args(\n",
        "        manual_output, np.min(manual_output), np.max(manual_output)\n",
        "    )\n",
        "    manual_output = tf.matmul(manual_output, w_quant)\n",
        "manual_output = tf.quantization.fake_quant_with_min_max_args(\n",
        "    manual_output, np.min(manual_output), np.max(manual_output)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOIYfnK5OkGv"
      },
      "source": [
        "# TFLite Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPDURL8EPB-F"
      },
      "source": [
        "# tflite computation\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(\n",
        "            10, use_bias=False, kernel_initializer=tf.initializers.constant(w)\n",
        "        )\n",
        "        for _ in range(N_LAYERS)\n",
        "    ]\n",
        ")\n",
        "model.build(x.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apNlAwDhOEQ0",
        "outputId": "fb419e71-d224-45ef-e1ca-edba5db4f6e3"
      },
      "source": [
        "def representative_dataset():\n",
        "    for i in range(x.shape[0]):\n",
        "        yield [x[[i]].astype(np.float32)]\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=converter.convert())\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "x_quant = np.round(x / input_scale + input_zero_point).astype(np.uint8)\n",
        "interpreter.set_tensor(input_details[\"index\"], x_quant)\n",
        "interpreter.invoke()\n",
        "tflite_output = interpreter.get_tensor(output_details[\"index\"])\n",
        "output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "tflite_output = (tflite_output.astype(np.float32) - output_zero_point) * output_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpxm29hg9o/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "burB6wxbOntc"
      },
      "source": [
        "# Comparing Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbo3jxWEN6Se",
        "outputId": "0c77c7f0-2c1d-48ae-a42a-ed50a5ff5610"
      },
      "source": [
        "# compare outputs\n",
        "outputs_close = np.allclose(manual_output, tflite_output, rtol=0, atol=1e-2)\n",
        "# Number of elements not within the tolerance\n",
        "num_mismatch = np.count_nonzero(~np.isclose(manual_output, tflite_output, rtol=0, atol=1e-2))\n",
        "err = np.abs(manual_output - tflite_output)\n",
        "with warnings.catch_warnings():\n",
        "    # Ignore \"divide by zero\" RuntimeWarning\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    err_rel = err / np.abs(tflite_output)\n",
        "# Filter out nan and inf created by dividing by 0\n",
        "err_rel = err_rel[np.isfinite(err_rel)]\n",
        "print(f\"--------------------- Manual vs TFLite ---------------------\")\n",
        "print(f\"Max Error: {np.max(err)}\")\n",
        "print(f\"Max Relative Error: {np.max(err_rel)}\")\n",
        "print(f\"Mean Error: {np.mean(err)}\")\n",
        "print(f\"Number of outputs outside tolerance: {num_mismatch/x.size*100}% of {x.size}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------- Manual vs TFLite ---------------------\n",
            "Max Error: 0.6615228652954102\n",
            "Max Relative Error: 1.014540195465088\n",
            "Mean Error: 0.1610247939825058\n",
            "Number of outputs outside tolerance: 93.4375% of 320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5QAO0LJOrYI"
      },
      "source": [
        "We see above that the error compounds with more layers"
      ]
    }
  ]
}