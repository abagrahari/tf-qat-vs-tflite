{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "id": "DE_hCD_Zn3jm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"tensorflow\", tf.__version__)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensorflow 2.5.0\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5olcN4GAeEb_",
    "outputId": "4ab1b21e-2a18-4f20-cd1c-06761b6b8965"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "id": "6310L2pRn9-1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some helper functions:\n",
    "- to convert between min/max quantization parameters, and tflite's scale/zero_point parameters.\n",
    "- to fake_quantize a tensor using `tf.quantization.fake_quant_with_min_max_vars`"
   ],
   "metadata": {
    "id": "obe1yMaBnlT4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def print_formatted(param: str, value: float):\n",
    "    print(f\"{param:35} {value:>15.6f}\")\n",
    "\n",
    "def calculate_min_max_from_tflite(\n",
    "    scale: float,\n",
    "    zero_point: int,\n",
    "    min_spec=-128,\n",
    "):\n",
    "    \"\"\"Calculate min/max from tflite params.\"\"\"\n",
    "    # Formula derived from fact that tflite quantizes\n",
    "    # `real_value = (int8_value - zero_point) * scale`, and setting\n",
    "    # int8_value to the range possible [minspec, 127] for int8\n",
    "    # See https://www.tensorflow.org/lite/performance/quantization_spec#int8_quantized_operator_specifications and https://arxiv.org/pdf/1712.05877.pdf\n",
    "    min = (min_spec - zero_point) * scale\n",
    "    max = (127 - zero_point) * scale\n",
    "    # FakeQuantWithMinMaxVars requires that 0.0 is always in the [min; max] range.\n",
    "    # See https://git.io/JWKjb\n",
    "    range_min = tf.math.minimum(min, 0.0)\n",
    "    range_max = tf.math.maximum(0.0, max)\n",
    "    return range_min, range_max\n",
    "\n",
    "def calculate_scale_zp_from_min_max(min, max):\n",
    "    \"\"\"Calculate scale and zero-point from asymmetric min/max.\n",
    "    Note: will not work for parameters created with narrow_range.\n",
    "    \"\"\"\n",
    "    quant_min=-128 # std::numeric_limits<int8_t>::min()\n",
    "    quant_max=127 # std::numeric_limits<int8_t>::max()\n",
    "    # scale = (max - min) / (2 ** 8 - 1) # formula from Section 3 in https://arxiv.org/pdf/1712.05877.pdf\n",
    "\n",
    "    # Below is borrowed from TfLite's GetAsymmetricQuantizationParams https://git.io/JBcVy\n",
    "    # Adjust the boundaries to guarantee 0 is included.\n",
    "    min = tf.math.minimum(min, 0)\n",
    "    max = tf.math.maximum(max, 0)\n",
    "    scale = (max - min) / (quant_max - quant_min)\n",
    "    zero_point_from_min = quant_min\n",
    "    if (scale != 0):\n",
    "        zero_point_from_min = quant_min - min / scale\n",
    "    if (zero_point_from_min < quant_min):\n",
    "        zero_point = quant_min\n",
    "    elif (zero_point_from_min > quant_max): \n",
    "        zero_point = quant_max\n",
    "    else:\n",
    "        zero_point = np.round(zero_point_from_min)\n",
    "    return scale, int(zero_point)\n",
    "\n",
    "\n",
    "def calculate_nudged_params(min, max, narrow_range=False):\n",
    "    \"\"\"Calculate nudged min,max, and scale from asymmetric min/max.\n",
    "    \"\"\"\n",
    "    # Below is borrowed from TF's FakeQuantWithMinMaxArgs https://git.io/JBCs4, https://git.io/JBCiI, https://git.io/JBCsQ\n",
    "    quant_min = 1 if narrow_range else 0\n",
    "    quant_max = (2**8) - 1 # 255\n",
    "    \n",
    "    # Nudge()\n",
    "    scale = (max - min) / (quant_max - quant_min);\n",
    "    zero_point_from_min = quant_min - min / scale\n",
    "    if zero_point_from_min < quant_min:\n",
    "        nudged_zero_point  = quant_min\n",
    "    elif zero_point_from_min > quant_max:\n",
    "        nudged_zero_point =  quant_max\n",
    "    else:\n",
    "        nudged_zero_point = tf.math.round(zero_point_from_min)\n",
    "    nudged_zero_point = int(nudged_zero_point) # will not match zp from GetAsymmetricQuantizationParams b/c of quant_min and quant_max values\n",
    "    nudged_min = (quant_min - nudged_zero_point) * scale\n",
    "    nudged_max = (quant_max - nudged_zero_point) * scale\n",
    "    # end Nudge()\n",
    "\n",
    "    return nudged_min, nudged_max, scale, nudged_zero_point\n",
    "    \n",
    "def fake_quant(\n",
    "    x: tf.Tensor,\n",
    "    scale: float,\n",
    "    zero_point: int,\n",
    "    bits=8,\n",
    "    narrow=False,\n",
    "    min_spec=-128,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"FakeQuantize a tensor using built-in tf functions and parameters from a tflite model.\n",
    "\n",
    "    Args:\n",
    "      x: tf.Tensor to quantize\n",
    "      scale: `scale` quantization parameter, from tflite\n",
    "      zero_point: `zero-point` quantization parameter, from tflite\n",
    "      bits: bitwidth of the quantization; between 2 and 16, inclusive\n",
    "      narrow: bool; narrow_range arg of fake_quant_with_min_max_vars\n",
    "      min_spec: 'min' value of the range of the quantized tensor, as defined in tflite's quantization spec\n",
    "    \"\"\"\n",
    "    range_min, range_max = calculate_min_max_from_tflite(scale, zero_point, min_spec)\n",
    "    return tf.quantization.fake_quant_with_min_max_vars(\n",
    "        x, range_min, range_max, num_bits=bits, narrow_range=narrow\n",
    "    )\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ],
   "outputs": [],
   "metadata": {
    "id": "J99ZBu30mXcV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the MNIST dataset, and normalize it."
   ],
   "metadata": {
    "id": "SVs2X2asmgEo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Normalize the images so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ],
   "outputs": [],
   "metadata": {
    "id": "btQuu15NmcX9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Base model"
   ],
   "metadata": {
    "id": "UCmuBFtdoFII"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "base_model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(10, use_bias=False),\n",
    "        keras.layers.Dense(10, use_bias=False),\n",
    "        keras.layers.Dense(10, use_bias=False),\n",
    "        keras.layers.Dense(10, use_bias=False),\n",
    "    ]\n",
    ")\n",
    "base_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "base_model.fit(train_images, train_labels, epochs=1, validation_split=0.1, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.5210 - accuracy: 0.8470 - val_loss: 0.2944 - val_accuracy: 0.9152\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ca2077370>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SYootskoJ0d",
    "outputId": "9ec49184-e57e-4cfd-db34-67427d93c204"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFLite Model"
   ],
   "metadata": {
    "id": "FR2WrXRWpAWE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create quantized model for TFLite from the base model\n",
    "def representative_dataset():\n",
    "    for data in (\n",
    "        tf.data.Dataset.from_tensor_slices(train_images)\n",
    "        .batch(1)\n",
    "        .take(-1)  # Use all of dataset\n",
    "    ):\n",
    "        yield [tf.dtypes.cast(data, tf.float32)]\n",
    "\n",
    "\n",
    "# Fully-integer INT8 converter settings\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8 for Coral\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8 for Coral\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr8922cs4/assets\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLXhpaaGkC92",
    "outputId": "d9158ba6-0f38-4f38-d3f4-b66d114a0f0f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get the scale&zero_point quantization parameters from the tflite model:"
   ],
   "metadata": {
    "id": "3r6MUcqsqYgk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "tflite_params = [{}, {}]\n",
    "# Flatten layer\n",
    "tflite_params[0][\"input_scale\"] = tensor_details[0][\"quantization\"][0]\n",
    "tflite_params[0][\"input_zp\"] = tensor_details[0][\"quantization\"][1]\n",
    "tflite_params[0][\"output_scale\"] = tensor_details[6][\"quantization\"][0]\n",
    "tflite_params[0][\"output_zp\"] = tensor_details[6][\"quantization\"][1]\n",
    "# First Dense layer\n",
    "tflite_params[1][\"input_scale\"] = tensor_details[6][\"quantization\"][0]\n",
    "tflite_params[1][\"input_zp\"] = tensor_details[6][\"quantization\"][1]\n",
    "tflite_params[1][\"kernel_scale\"] = tensor_details[2][\"quantization\"][0]\n",
    "tflite_params[1][\"kernel_zp\"] = tensor_details[2][\"quantization\"][1]\n",
    "tflite_params[1][\"output_scale\"] = tensor_details[7][\"quantization\"][0]\n",
    "tflite_params[1][\"output_zp\"] = tensor_details[7][\"quantization\"][1]"
   ],
   "outputs": [],
   "metadata": {
    "id": "CH13JdgrqTSG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual Computation"
   ],
   "metadata": {
    "id": "rFgjZ2M3pmzU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can manually perform the computations of the Flatten layer + the first Dense layer.\n",
    "Then, we can compare the min/max of this output to the previously extracted min/max params of the tflite model.\n",
    "\n",
    "For an input `x` and kernel `w`, I manually compute `tf.matmul(x, w)` and then compute the scale/zp of the result"
   ],
   "metadata": {
    "id": "Qam8__BKpJfB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Use all the mnist train_images\n",
    "kernel = base_model.weights[0]  # Get kernel from base model\n",
    "# As per TfLite's QuantizeModel https://git.io/J4hxt, it seems that a full fp32 forward pass is done first\n",
    "# after which, quantization parameters are independantly calculated.\n",
    "outputs = []\n",
    "for image in train_images:\n",
    "    # Flatten image\n",
    "    image = tf.cast(tf.reshape(image, [-1, 784]), tf.float32)\n",
    "    assert image.shape == (1, 784)\n",
    "    y: tf.Tensor = tf.matmul(image, kernel)\n",
    "    assert y.shape == (1, 10)\n",
    "    # no bias adddition\n",
    "    # linear activation function - thus, don't apply anything\n",
    "    outputs.append(y)\n",
    "outputs = np.array(outputs)"
   ],
   "outputs": [],
   "metadata": {
    "id": "ozmXfLQhpIMH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(\"\\nParameters from manual computation\")\n",
    "params = calculate_scale_zp_from_min_max(np.min(outputs),np.max(outputs))\n",
    "print(f\"Scale: {params[0]}, Zero-point: {params[1]}\")\n",
    "\n",
    "print(\"\\nParameters from tflite model\")\n",
    "params = (tflite_params[1]['output_scale'],tflite_params[1]['output_zp'])\n",
    "print(f\"Scale: {params[0]}, Zero-point: {params[1]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Parameters from manual computation\n",
      "Scale: 0.09184519946575165, Zero-point: -3\n",
      "\n",
      "Parameters from tflite model\n",
      "Scale: 0.09184519946575165, Zero-point: -3\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "is_AxEo2M4wa",
    "outputId": "3a920b1e-f4a6-4581-aa13-9ce699b501c2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "Let's look at the `max/min` parameters instead. \n",
    "\n",
    "For TfLite - we will compute the `min/max` from the `scale/zp` params.\n",
    "\n",
    "For the manual computation - we will look at the `min/max` of the outputs.\n",
    "We will also convert this `min/max` to `scale/zp`, and then convert back to `min/max`. This is to \n",
    "account for the loss of info when converting from `min/max` to `scale/zp` since `zp` is an `int8`"
   ],
   "metadata": {
    "id": "t1ELhtkspeeX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"\\nParameters from manual computation\")\n",
    "params = (np.min(outputs),np.max(outputs))\n",
    "print(f\"True Min: {params[0]}, True Max: {params[1]}\")\n",
    "\n",
    "params = calculate_min_max_from_tflite(*calculate_scale_zp_from_min_max(*params))\n",
    "print(f\"Adjusted Min: {params[0]}, Adjusted Max: {params[1]}\")\n",
    "\n",
    "params = calculate_nudged_params(np.min(outputs),np.max(outputs))\n",
    "print(f\"Nudged Min: {params[0]}, Nudged Max: {params[1]}, Scale: {params[2]}\")\n",
    "\n",
    "\n",
    "print(\"\\nParameters from tflite model\")\n",
    "params = (tflite_params[1]['output_scale'],tflite_params[1]['output_zp'])\n",
    "params = calculate_min_max_from_tflite(*params)\n",
    "print(f\"Min: {params[0]}, Max: {params[1]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Parameters from manual computation\n",
      "True Min: -11.477302551269531, True Max: 11.94322395324707\n",
      "Adjusted Min: -11.480649948120117, Adjusted Max: 11.939875602722168\n",
      "Nudged Min: -11.48065024731206, Nudged Max: 11.939876257204542, Scale: 0.09184520197849648\n",
      "\n",
      "Parameters from tflite model\n",
      "Min: -11.480649948120117, Max: 11.939875602722168\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the true min/max don't match with tflite, it looks like the 'adjusted' and 'nudged' versions do."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tflite_quant_params.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "1dd3f7e8b9281c263f9ccce33e0991d02fffaeb6afe0c0436aa5cbe473145776"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf-exp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}