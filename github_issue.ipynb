{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tflite_quant_params.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE_hCD_Zn3jm"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5olcN4GAeEb_",
        "outputId": "4ab1b21e-2a18-4f20-cd1c-06761b6b8965"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"tensorflow\", tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6310L2pRn9-1"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obe1yMaBnlT4"
      },
      "source": [
        "Some helper functions:\n",
        "- to convert between min/max quantization parameters, and tflite's scale/zero_point parameters.\n",
        "- to fake_quantize a tensor using `tf.quantization.fake_quant_with_min_max_vars`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J99ZBu30mXcV"
      },
      "source": [
        "def print_formatted(param: str, value: float):\n",
        "    print(f\"{param:35} {value:>15.6f}\")\n",
        "\n",
        "def calculate_min_max_from_tflite(\n",
        "    scale: float,\n",
        "    zero_point: int,\n",
        "    min_spec=-128,\n",
        "):\n",
        "    \"\"\"Calculate min/max from tflite params.\"\"\"\n",
        "    # Formula derived from fact that tflite quantizes\n",
        "    # `real_value = (int8_value - zero_point) * scale`, and setting\n",
        "    # int8_value to the range possible [minspec, 127] for int8\n",
        "    # See https://www.tensorflow.org/lite/performance/quantization_spec#int8_quantized_operator_specifications  and https://arxiv.org/pdf/1712.05877.pdf\n",
        "    min = (min_spec - zero_point) * scale\n",
        "    max = (127 - zero_point) * scale\n",
        "    # FakeQuantWithMinMaxVars requires that 0.0 is always in the [min; max] range.\n",
        "    # See https://git.io/JWKjb\n",
        "    range_min = tf.math.minimum(min, 0.0)\n",
        "    range_max = tf.math.maximum(0.0, max)\n",
        "    return range_min, range_max\n",
        "\n",
        "def calculate_scale_zp_from_min_max(min, max):\n",
        "    \"\"\"Calculate scale and zero-point from min/max.\n",
        "    Note: will not work for parameters created with narrow_range.\n",
        "    \"\"\"\n",
        "    # Below formula is from Section 3 in https://arxiv.org/pdf/1712.05877.pdf\n",
        "    scale = (max - min) / (2 ** 8 - 1)\n",
        "    # Below formula is rearrangment of calculate_min_max_from_tflite\n",
        "    zero_point = 127 - max / scale\n",
        "    return scale, zero_point\n",
        "    \n",
        "def fake_quant(\n",
        "    x: tf.Tensor,\n",
        "    scale: float,\n",
        "    zero_point: int,\n",
        "    bits=8,\n",
        "    narrow=False,\n",
        "    min_spec=-128,\n",
        ") -> tf.Tensor:\n",
        "    \"\"\"FakeQuantize a tensor using built-in tf functions and parameters from a tflite model.\n",
        "\n",
        "    Args:\n",
        "      x: tf.Tensor to quantize\n",
        "      scale: `scale` quantization parameter, from tflite\n",
        "      zero_point: `zero-point` quantization parameter, from tflite\n",
        "      bits: bitwidth of the quantization; between 2 and 16, inclusive\n",
        "      narrow: bool; narrow_range arg of fake_quant_with_min_max_vars\n",
        "      min_spec: 'min' value of the range of the quantized tensor, as defined in tflite's quantization spec\n",
        "    \"\"\"\n",
        "    range_min, range_max = calculate_min_max_from_tflite(scale, zero_point, min_spec)\n",
        "    return tf.quantization.fake_quant_with_min_max_vars(\n",
        "        x, range_min, range_max, num_bits=bits, narrow_range=narrow\n",
        "    )\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVs2X2asmgEo"
      },
      "source": [
        "Load the MNIST dataset, and normalize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btQuu15NmcX9"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Normalize the images so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCmuBFtdoFII"
      },
      "source": [
        "# Base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SYootskoJ0d",
        "outputId": "9ec49184-e57e-4cfd-db34-67427d93c204"
      },
      "source": [
        "base_model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(10, use_bias=False),\n",
        "        keras.layers.Dense(10, use_bias=False),\n",
        "        keras.layers.Dense(10, use_bias=False),\n",
        "        keras.layers.Dense(10, use_bias=False),\n",
        "    ]\n",
        ")\n",
        "base_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "base_model.fit(train_images, train_labels, epochs=1, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5210 - accuracy: 0.8470 - val_loss: 0.2944 - val_accuracy: 0.9152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5749196110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR2WrXRWpAWE"
      },
      "source": [
        "# TFLite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLXhpaaGkC92",
        "outputId": "d9158ba6-0f38-4f38-d3f4-b66d114a0f0f"
      },
      "source": [
        "# Create quantized model for TFLite from the base model\n",
        "def representative_dataset():\n",
        "    for data in (\n",
        "        tf.data.Dataset.from_tensor_slices(train_images)\n",
        "        .batch(1)\n",
        "        .take(-1)  # Use all of dataset\n",
        "    ):\n",
        "        yield [tf.dtypes.cast(data, tf.float32)]\n",
        "\n",
        "\n",
        "# Fully-integer INT8 converter settings\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8 for Coral\n",
        "converter.inference_output_type = tf.int8  # or tf.uint8 for Coral\n",
        "converter.representative_dataset = representative_dataset\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2gp8aosh/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2gp8aosh/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r6MUcqsqYgk"
      },
      "source": [
        "We get the scale&zero_point quantization parameters from the tflite model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH13JdgrqTSG"
      },
      "source": [
        "\n",
        "tensor_details = interpreter.get_tensor_details()\n",
        "tflite_params = [{}, {}]\n",
        "# Flatten layer\n",
        "tflite_params[0][\"input_scale\"] = tensor_details[0][\"quantization\"][0]\n",
        "tflite_params[0][\"input_zp\"] = tensor_details[0][\"quantization\"][1]\n",
        "tflite_params[0][\"output_scale\"] = tensor_details[6][\"quantization\"][0]\n",
        "tflite_params[0][\"output_zp\"] = tensor_details[6][\"quantization\"][1]\n",
        "# First Dense layer\n",
        "tflite_params[1][\"input_scale\"] = tensor_details[6][\"quantization\"][0]\n",
        "tflite_params[1][\"input_zp\"] = tensor_details[6][\"quantization\"][1]\n",
        "tflite_params[1][\"kernel_scale\"] = tensor_details[2][\"quantization\"][0]\n",
        "tflite_params[1][\"kernel_zp\"] = tensor_details[2][\"quantization\"][1]\n",
        "tflite_params[1][\"output_scale\"] = tensor_details[7][\"quantization\"][0]\n",
        "tflite_params[1][\"output_zp\"] = tensor_details[7][\"quantization\"][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFgjZ2M3pmzU"
      },
      "source": [
        "# Manual Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qam8__BKpJfB"
      },
      "source": [
        "We can manually perform the computations of the Flatten layer + the first Dense layer.\n",
        "Then, we can compare the min/max of this output to the previously extracted min/max params of the tflite model.\n",
        "\n",
        "For an input `x` and kernel `w`, I manually compute `tf.matmul(x, w)` and then compute the scale/zp of the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmXfLQhpIMH"
      },
      "source": [
        "# Use all the mnist train_images\n",
        "kernel = base_model.weights[0]  # Get kernel from base model\n",
        "# FakeQuant kernel based on params from tflite model\n",
        "fq_kernel = fake_quant(\n",
        "    kernel,\n",
        "    tflite_params[1][\"kernel_scale\"],\n",
        "    tflite_params[1][\"kernel_zp\"],\n",
        "    narrow=True,  # tflite spec says it uses narrow_range for weights, with below value\n",
        "    min_spec=-127,\n",
        ")\n",
        "outputs = []\n",
        "for image in train_images:\n",
        "    # Flatten image\n",
        "    image = tf.cast(tf.reshape(image, [-1, 784]), tf.float32)\n",
        "    assert image.shape == (1, 784)\n",
        "    fq_input = fake_quant(image, tflite_params[0][\"input_scale\"], tflite_params[0][\"input_zp\"])\n",
        "    y: tf.Tensor = tf.matmul(fq_input, fq_kernel)\n",
        "    assert y.shape == (1, 10)\n",
        "    # no bias adddition\n",
        "    # linear activation function - thus, don't apply anything\n",
        "    # Not fakeQuantizing outputs, in order to compare min/max params\n",
        "    outputs.append(y)\n",
        "outputs = np.array(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is_AxEo2M4wa",
        "outputId": "3a920b1e-f4a6-4581-aa13-9ce699b501c2"
      },
      "source": [
        "print(\"\\nParameters from manual computation\")\n",
        "params = calculate_scale_zp_from_min_max(np.min(outputs),np.max(outputs))\n",
        "print(f\"Scale: {params[0]}, Zero-point: {params[1]}\")\n",
        "\n",
        "print(\"\\nParameters from tflite model\")\n",
        "params = (tflite_params[1]['output_scale'],tflite_params[1]['output_zp'])\n",
        "print(f\"Scale: {params[0]}, Zero-point: {params[1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parameters from manual computation\n",
            "Scale: 0.09185781291886871, Zero-point: -3.0351044277537085\n",
            "\n",
            "Parameters from tflite model\n",
            "Scale: 0.09184519201517105, Zero-point: -3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ELhtkspeeX"
      },
      "source": [
        "And, it appears that the tflite model parameters don't match my expected values."
      ]
    }
  ]
}